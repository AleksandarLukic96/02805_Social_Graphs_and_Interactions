{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306f5fbb",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a132f9",
   "metadata": {},
   "source": [
    "## Python setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0f5607fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import re\n",
    "import urllib.request as req"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc76a49",
   "metadata": {},
   "source": [
    "## Exercises Part 1: Regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24a07a5",
   "metadata": {},
   "source": [
    "### 1.1 Tutorial in RegEx\n",
    "_Honestly, this [youtube](https://www.youtube.com/watch?v=rhzKDrUiJVk) guide is waaaayyyy better than the google guide..._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e961a",
   "metadata": {},
   "source": [
    "Regular expressions are a powerful language for matching text patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfec579",
   "metadata": {},
   "source": [
    "The Python \"re\" module provides regular expression support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cddf59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If-statement after search() tests if it succeeded\n",
    "def check_regex(match):\n",
    "    if match:\n",
    "      print('found:', match.group())\n",
    "    else:\n",
    "      print('did not find')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0bd65",
   "metadata": {},
   "source": [
    "In RegEx, we are interested in using a pattern, 'pat', to search through a text, 'str'. The pattern is defined as an regular expression based on a defined syntax. In python's 're' library, each pattern starts with a 'r' followed by the expression. \n",
    "\n",
    "_Note that the syntax in python is a bit different than traditional RegEx!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89384c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found: alice-b@google.com\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice-b@google.com monkey dishwasher'\n",
    "pat = r'([\\w.-]+)@([\\w.-]+)'\n",
    "\n",
    "# The re.search() function returns a match type, which contains groups\n",
    "match = re.search(pat, str)\n",
    "\n",
    "check_regex(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da59f2",
   "metadata": {},
   "source": [
    "Group Extraction - We can split our result into groups and then extract them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6270841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice-b@google.com\n",
      "alice-b\n",
      "google.com\n"
     ]
    }
   ],
   "source": [
    "print(match.group(0)) # (the whole match)\n",
    "print(match.group(1)) # (the username, group 1)\n",
    "print(match.group(2)) # (the host, group 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af948ec8",
   "metadata": {},
   "source": [
    "The most powerful function in re is findall(), which returns a list of regex results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1e2f9c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice@google.com\n",
      "bob@abc.com\n"
     ]
    }
   ],
   "source": [
    "## Suppose we have a text with many email addresses\n",
    "str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "\n",
    "pat = r'([\\w\\.-]+@[\\w\\.-]+)'\n",
    "\n",
    "## Here re.findall() returns a list of all the found email strings\n",
    "emails = re.findall(pat, str) ## ['alice@google.com', 'bob@abc.com']\n",
    "\n",
    "for email in emails:\n",
    "    # do something with each found email string\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b76a2e",
   "metadata": {},
   "source": [
    "The findall function can also be used on files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2240f59e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Enter Barnardo and Francisco, two sentinels.',\n",
       " 'Enter Horatio and Marcellus.']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open file\n",
    "f = open('../files/hamlet_act_1_scene_1.txt', encoding='utf-8')\n",
    "\n",
    "# Get only scenographic instructions, marked by '(...)'\n",
    "pat = r'\\(([^)]+)\\)'\n",
    "\n",
    "# Feed the file text into findall(); it returns a list of all the found strings\n",
    "strings = re.findall(pat, f.read())\n",
    "strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296b708",
   "metadata": {},
   "source": [
    "Findall and Groups can be used to sub divide the search results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d70c7ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('alice', 'google.com'), ('bob', 'abc.com')]\n",
      "Username: \"alice\", Host: \"google.com\"\n",
      "Username: \"bob\", Host: \"abc.com\"\n"
     ]
    }
   ],
   "source": [
    "str = 'purple alice@google.com, blah monkey bob@abc.com blah dishwasher'\n",
    "pat = r'([\\w\\.-]+)@([\\w\\.-]+)'\n",
    "\n",
    "tuples = re.findall(pat, str)\n",
    "\n",
    "print(tuples)  ## [('alice', 'google.com'), ('bob', 'abc.com')]\n",
    "\n",
    "for tuple in tuples:\n",
    "    print(f\"Username: \\\"{tuple[0]}\\\", Host: \\\"{tuple[1]}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947bead5",
   "metadata": {},
   "source": [
    "### 1.2 What are regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc7671",
   "metadata": {},
   "source": [
    "A regular expression is a string, which follows a predefined syntax that enables pattern recognition in texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a354fa",
   "metadata": {},
   "source": [
    "### 1.3 RegEx on 4-digit numbers from URL text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364574a",
   "metadata": {},
   "source": [
    "Find all 4-digit numbers in [this text](https://raw.githubusercontent.com/SocialComplexityLab/socialgraphs2020/master/files/regex_exercise.txt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c0d4ff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the url\n",
    "url = \"https://raw.githubusercontent.com/SocialComplexityLab/socialgraphs2020/master/files/regex_exercise.txt\"\n",
    "\n",
    "# Get HTTPResponse from url\n",
    "data = req.urlopen(url)\n",
    "\n",
    "# Extract byte string from reponse data\n",
    "byte_string = data.read()\n",
    "\n",
    "# Decode byte string to regular string\n",
    "text = byte_string.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f149f1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234\n",
      "9999\n"
     ]
    }
   ],
   "source": [
    "# Get only 4-digit numbers\n",
    "pat = r'(?<!\\d)\\d{4}(?!\\d)'\n",
    "\n",
    "# Feed the file text into findall(); it returns a list of all the found strings\n",
    "numbers = re.findall(pat, text)\n",
    "\n",
    "# Print digist one at a time on new lines \n",
    "print(*numbers, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a8fc16",
   "metadata": {},
   "source": [
    "### 1.4 RegEx for words starting with 'super' from URL text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "ee4b05a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "superpolaroid\n",
      "supertaxidermy\n",
      "superbeer\n"
     ]
    }
   ],
   "source": [
    "# Get only words starting with 'super'\n",
    "pat = r'super[\\w+]*'\n",
    "\n",
    "# Feed the file text into findall(); it returns a list of all the found strings\n",
    "words = re.findall(pat, text)\n",
    "\n",
    "# Print digist one at a time on new lines \n",
    "print(*words, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145c6c99",
   "metadata": {},
   "source": [
    "### 1.5 RegEx find Wiki links in URL text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "32643e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches:\n",
      "  drinking vinegar\n",
      "  gentrify\n",
      "  hashtag\n",
      "  Bicycle|Bicycle(two-wheeled type)\n",
      "  Pitchfork|Pitchfork Magazine\n",
      "Results:\n",
      "  drinking vinegar\n",
      "  gentrify\n",
      "  hashtag\n",
      "  Bicycle\n",
      "  Bicycle\n",
      "  Pitchfork\n",
      "  Pitchfork Magazine\n",
      "Urls:\n",
      "  https://en.wikipedia.org/wiki/drinking_vinegar\n",
      "  https://en.wikipedia.org/wiki/gentrify\n",
      "  https://en.wikipedia.org/wiki/hashtag\n",
      "  https://en.wikipedia.org/wiki/Bicycle\n",
      "  https://en.wikipedia.org/wiki/Pitchfork\n",
      "  https://en.wikipedia.org/wiki/Pitchfork_Magazine\n"
     ]
    }
   ],
   "source": [
    "# Get any strings surrounded by '[[...]]'\n",
    "pat = r'\\[\\[(.*?)\\]\\]'    \n",
    "matches = re.findall(pat, text)\n",
    "print(\"Matches:\", *matches, sep=\"\\n  \")\n",
    "\n",
    "# List to hold the final substrings\n",
    "results = []\n",
    "for match in matches:\n",
    "    # Remove content in parentheses and split by '|'\n",
    "    cleaned_substrings = re.sub(r'\\s*\\(.*?\\)\\s*', '', match).split('|')\n",
    "    results.extend(cleaned_substrings)\n",
    "print(\"Results:\", *results, sep=\"\\n  \")\n",
    "\n",
    "# Create urls from wiki links one at a time while replacing spaces with '_' \n",
    "urls = []\n",
    "for res in results:\n",
    "    urls.append(\"https://en.wikipedia.org/wiki/\" + res.replace(\" \", \"_\"))\n",
    "\n",
    "# Remove dublicate urls\n",
    "urls = list(dict.fromkeys(urls))\n",
    "\n",
    "# print out urls\n",
    "print(\"Urls:\", *urls, sep=\"\\n  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab1a74",
   "metadata": {},
   "source": [
    "## Exercises Part 2: Download the Wikipedia pages of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33c9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
